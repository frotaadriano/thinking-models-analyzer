# ğŸ§  Thinking Models Analyzer

AplicaÃ§Ã£o **Streamlit** para explorar, comparar e avaliar diferentes **abordagens de prompts** (Chain of Thought, Skeleton of Thought, Tree of Thought, Self-consistency, Zero-shot e Few-shot).  
Inclui um mÃ³dulo de **Experimentos & Benchmark** que permite testar casos reais, salvar tentativas em JSONL local e gerar ranking das abordagens.

---

## ğŸš€ Funcionalidades

- **VisÃ£o geral das abordagens**: explicaÃ§Ã£o, quando usar, exemplos e template de prompt.
- **RecomendaÃ§Ã£o com Azure OpenAI (opcional)**: IA sugere a melhor abordagem para um contexto especÃ­fico.
- **Experimentos & Benchmark**:
  - CRUD de casos (com pesos de mÃ©tricas customizÃ¡veis).
  - ExecuÃ§Ã£o de testes com vÃ¡rias abordagens e repetiÃ§Ãµes.
  - ExecuÃ§Ã£o via **Azure OpenAI** ou **heurÃ­stica local simulada**.
  - Registro de resultados em arquivos **JSONL locais** (`data/cases.jsonl`, `runs.jsonl`, `attempts.jsonl`).
  - AvaliaÃ§Ã£o manual (nota 1â€“5, observaÃ§Ãµes).
  - Ranking automÃ¡tico com pesos normalizados (Qualidade, Tempo, Tokens).
  - ExportaÃ§Ã£o em **CSV** ou **JSON**.

---

## ğŸ“¦ InstalaÃ§Ã£o

### 1. Clone o repositÃ³rio
```bash
git clone https://github.com/seu-usuario/thinking-models-analyzer.git
cd thinking-models-analyzer
```

### 2. Crie e ative um ambiente virtual
Linux/macOS:
```bash
ppython -m venv .thinkvenv
source .thinkvenv/bin/activate # On Windows: .thinkvenv\Scripts\activate
```

Windows (PowerShell):
```powershell
python -m venv .venv
.venv\Scripts\Activate
```

### 3. Instale as dependÃªncias
```bash
pip install -r requirements.txt
```

---

## ğŸ“‘ Arquivo `requirements.txt`

```txt
streamlit>=1.34.0
openai>=1.30.0
jsonlines>=4.0.0
python-dotenv>=1.0.1
plotly>=5.22.0
pandas>=2.2.0
```

---

## âš™ï¸ ConfiguraÃ§Ã£o Azure OpenAI (opcional)

Crie um arquivo `.env` na raiz do projeto com:

```ini
AZURE_OPENAI_ENDPOINT=https://<seu-recurso>.openai.azure.com/
AZURE_OPENAI_API_KEY=<sua_chave_api>
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4o-mini
AZURE_OPENAI_API_VERSION=2024-02-15-preview
```

> Se nÃ£o configurar, a aplicaÃ§Ã£o funcionarÃ¡ no **modo heurÃ­stico local**.

---

## â–¶ï¸ Executando a aplicaÃ§Ã£o

```bash
streamlit run streamlit_app_full.py
```

Acesse em: [http://localhost:8501](http://localhost:8501)

---

## ğŸ“‚ Estrutura do projeto

```
thinking-models-analyzer/
â”‚
â”œâ”€â”€ streamlit_app_full.py     # CÃ³digo principal da aplicaÃ§Ã£o
â”œâ”€â”€ requirements.txt          # DependÃªncias do projeto
â”œâ”€â”€ README.md                 # Este arquivo
â”œâ”€â”€ .env.example              # Exemplo de configuraÃ§Ã£o do Azure OpenAI
â””â”€â”€ data/                     # DiretÃ³rio com JSONL persistidos (criado em runtime)
    â”œâ”€â”€ cases.jsonl
    â”œâ”€â”€ runs.jsonl
    â””â”€â”€ attempts.jsonl
```

---

## ğŸ› ï¸ Roadmap futuro

- Adicionar suporte a **exemplos Few-shot customizÃ¡veis** por caso.
- Persistir mÃ©tricas adicionais (custo estimado por execuÃ§Ã£o).
- Dashboard de comparaÃ§Ãµes entre mÃºltiplos casos.

---

## ğŸ“œ LicenÃ§a

MIT â€” fique Ã  vontade para usar, modificar e compartilhar.

---
